{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "c6cc6a17-79f3-41ee-9579-f36b17048130",
   "metadata": {},
   "source": [
    "# Imports"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "e874325a-9785-4fa7-8f7f-02faa214637b",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "import torch.optim as optim\n",
    "from torch.utils.data import DataLoader\n",
    "from torchvision import datasets\n",
    "from torchvision.transforms import ToTensor\n",
    "from torchvision import datasets, transforms\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "from tqdm import tqdm\n",
    "\n",
    "import os\n",
    "import pandas as pd\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "\n",
    "pd.reset_option('display.max_rows')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "676df57e-9565-497f-b7bc-559faeb9d176",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using cpu device\n"
     ]
    }
   ],
   "source": [
    "if torch.cuda.is_available():\n",
    "    device = \"cuda\"\n",
    "else:\n",
    "    device = \"cpu\"\n",
    "\n",
    "print(f\"Using {device} device\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3a9acaa3-a4fa-43e5-88f1-3307eb4152db",
   "metadata": {},
   "outputs": [],
   "source": [
    "transform = transforms.Compose([\n",
    "    transforms.Grayscale(num_output_channels=1),   # Convert to grayscale if necessary\n",
    "    transforms.Resize((28, 28)),\n",
    "    transforms.ToTensor(),\n",
    "    transforms.Normalize((0.5,), (0.5,))           # Normalize to mean=0.5, std=0.5 for grayscale\n",
    "])\n",
    "\n",
    "# Load dataset\n",
    "train_dataset = datasets.ImageFolder(root='path_to_your_train_folder', transform=transform)\n",
    "test_dataset = datasets.ImageFolder(root='path_to_your_test_folder', transform=transform)\n",
    "\n",
    "# DataLoader\n",
    "train_loader = DataLoader(train_dataset, batch_size=200, shuffle=True)\n",
    "test_loader = DataLoader(test_dataset, batch_size=200, shuffle=False)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "50c84007-594f-4b57-889b-a3dc31a5fed3",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "ebf84304-b2a6-4197-8273-c4da4ed9d8b9",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CNN(\n",
      "  (convolutional_layers): Sequential(\n",
      "    (0): Conv2d(1, 32, kernel_size=(5, 5), stride=(1, 1), padding=(2, 2))\n",
      "    (1): ReLU(inplace=True)\n",
      "    (2): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
      "    (3): Conv2d(32, 64, kernel_size=(5, 5), stride=(1, 1), padding=(2, 2))\n",
      "    (4): ReLU(inplace=True)\n",
      "    (5): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
      "  )\n",
      "  (fully_connected_layer1): Sequential(\n",
      "    (0): Linear(in_features=3136, out_features=1024, bias=True)\n",
      "    (1): ReLU(inplace=True)\n",
      "  )\n",
      "  (dropout): Dropout(p=0.4, inplace=False)\n",
      "  (fully_connected_layer2): Linear(in_features=1024, out_features=10, bias=True)\n",
      ")\n"
     ]
    }
   ],
   "source": [
    "class CNN(nn.Module):\n",
    "    def __init__(self,drop):\n",
    "        super(CNN, self).__init__()\n",
    "        self.drop = drop\n",
    "\n",
    "        self.convolutional_layers = nn.Sequential(\n",
    "            nn.Conv2d(1, 32, kernel_size=5, stride=1, padding=2),                # Convolutional layer with 32 kernels, window size 5, padding size 2, stride 1\n",
    "            nn.ReLU(inplace=True),                                               # In place ReLU activation layer\n",
    "            nn.MaxPool2d(kernel_size=2, stride=2),                               # Max pooling layer with window size 2, stride 2\n",
    "            nn.Conv2d(32, 64, kernel_size=5, stride=1, padding=2),               # Convolutional layer with 64 kernels, window size 5, padding size 2, stride 1\n",
    "            nn.ReLU(inplace=True),                                               # Second In-place ReLU activation\n",
    "            nn.MaxPool2d(kernel_size=2, stride=2),                               # Max pooling layer with window size 2, stride 2\n",
    "        )\n",
    "\n",
    "                                                                                # Since torch.Size([1, 28, 28])\n",
    "                                                                                # H = 28, W = 28 and C = 1 (Height, Width, number of channels)\n",
    "                                                                                # After the first pooling step, H=28/2 = 14, W=28/2= 14 and C=1\n",
    "                                                                                # After the second pooling step, H=14/2=7, W=14/2=7 and C=1\n",
    "                                                                                # Depth = 64 because size of the kernel in the second conv layer is 64\n",
    "                                                                                # Dimensions of features 7 * 7 * 64\n",
    "        self.fully_connected_layer1 = nn.Sequential(\n",
    "            nn.Linear(3136, 1024),                                               # Fully connected layer with 1024 output channels\n",
    "            nn.ReLU(inplace= True)                                                # In place ReLU activation layer\n",
    "\n",
    "       )\n",
    "        self.dropout = nn.Dropout(p = 0.4)                                        # Dropout layer with drop rate 0.4\n",
    "        self.fully_connected_layer2 = nn.Linear(1024, 10)                         # Fully connected layer with 10 output channels and 1024 inputs from prev pooling step\n",
    "\n",
    "    def forward(self, x):\n",
    "        input = self.convolutional_layers(x)                                     # apply conv layers\n",
    "        input = input.reshape(-1, 3136)                                          # reshape\n",
    "        input =  self.fully_connected_layer1(input)                              # apply fc layeer 1\n",
    "        if(self.drop == True):                                                   # is dropout needed ?\n",
    "          #print(\"applied Dropout\")\n",
    "          input = self.dropout(input)\n",
    "\n",
    "        input = self.fully_connected_layer2(input)                                 # apply fc 2\n",
    "        return input\n",
    "\n",
    "# Print net\n",
    "net = CNN(drop=True).to(device)\n",
    "print(net)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "f16bb231-e11b-4519-8ced-84d3d4967eec",
   "metadata": {},
   "outputs": [],
   "source": [
    "def train(train_dataset, net, to_train, opt, epochs=10, batch=200, learning_rate=1e-3):\n",
    "    # Initialize loss\n",
    "    criterion = nn.CrossEntropyLoss()\n",
    "    losslist = []\n",
    "    acclist=[]\n",
    "\n",
    "    # Create dataloader\n",
    "    MNIST_train_dataloader = DataLoader(train_dataset, batch_size=batch, shuffle=True)\n",
    "\n",
    "    # Select optimizer\n",
    "    if(opt=='adam'):\n",
    "        optimizer = optim.Adam(to_train,lr=learning_rate)\n",
    "    else:\n",
    "        optimizer = optim.SGD(to_train,lr=learning_rate,momentum = 0.99)\n",
    "    optimizer.zero_grad()\n",
    "\n",
    "    # Set model to training mode\n",
    "    net.train()\n",
    "    for k in tqdm(range(epochs)):\n",
    "        for it, (X,y) in enumerate(MNIST_train_dataloader):\n",
    "            # Send to device\n",
    "            X, y = X.to(device), y.to(device)\n",
    "\n",
    "            # Train the model using the optimizer and the batch data.\n",
    "            # Append the loss and accuracy from each iteration to the losslist and acclist arrays\n",
    "            optimizer.zero_grad()                                                # Resets the gradients of all optimized torch.Tensor s\n",
    "            pred_outputs = net(X)                                                # forward pass: [output] forward(input, target)\n",
    "            curr_loss = criterion(pred_outputs, y)                               # applying the loss function\n",
    "            curr_loss.backward()                                                 # backward pass: [gradInput] backward(input, target)\n",
    "            optimizer.step()                                                     # reevaluates the model and returns the loss.\n",
    "\n",
    "\n",
    "            # print(curr_loss.item())\n",
    "            # print(y)\n",
    "            # loss_value = curr_loss[0]\n",
    "            loss_value = curr_loss.item()                                        # get current batch loss\n",
    "            losslist.append(loss_value)                                          # append curr value to list\n",
    "\n",
    "            predicted = pred_outputs.argmax(dim=1)                               # getting predicted class labels from output of the nn\n",
    "            is_correct_prediction = (predicted == y)                             # element wise check if predicted == y\n",
    "            correct_predictions = is_correct_prediction.sum().item()             # counts the number of correct predictions and convert to python scalar\n",
    "            batch_size = y.size(0)                                               # get batch size\n",
    "            curr_accuracy = correct_predictions /  batch_size                    # compute the current accuracy\n",
    "            acclist.append(curr_accuracy)\n",
    "\n",
    "    return losslist,acclist\n",
    "\n",
    "# Used to test or evaluate your network. Already written for you.\n",
    "def test(test_dataset, net):\n",
    "    batch = 200\n",
    "    test_dataloader = DataLoader(test_dataset, batch_size=batch)\n",
    "    size = len(test_dataloader.dataset)\n",
    "\n",
    "    # Set model to eval mode\n",
    "    net.eval()\n",
    "\n",
    "    test_loss, correct = 0, 0\n",
    "    with torch.no_grad():\n",
    "        for X, y in test_dataloader:\n",
    "            # Send to device\n",
    "            X, y = X.to(device), y.to(device)\n",
    "\n",
    "            # Prediction\n",
    "            pred = net(X)\n",
    "\n",
    "            # Calculate number of correct predictions in the batch\n",
    "            correct += (pred.argmax(1) == y).type(torch.float).sum().item()\n",
    "\n",
    "    # Compute total accuracy\n",
    "    acc = correct / size\n",
    "    return acc"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9134e270-a5e1-4ed4-bc90-617fd10f440b",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
